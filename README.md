# **Building Multi-Agent Systems**

> **Youtube Video:** [Building Multi-Agent Systems - YouTube](https://www.youtube.com/watch?v=n5vYcVVIurg)

Multi-agent systems are fascinating. I once asked myself: what can multiple agents accomplish that a single agent cannot? I was wrong. 

> **Research Insight:** Anthropic's research shows that a multi-agent system with Claude Opus 4 as the lead agent and Claude Sonnet 4 subagents outperformed single-agent Claude Opus 4 by 90.2% on their internal research evaluation.

<p align="center">
  <img src="/assets/main.png" alt="Multi-Agent System" width="85%">
</p>

Multi-agent architectures are everywhere likely the deep research features from ChatGPT, Gemini, Perplexity and Grok all leverage multi-agent approaches under the hood.



## **Step One: Multi means many**

> Multi means many, but more importantly, it means specialized.

A common pitfall when building multi-agent systems is expecting each agent to be a generalist. While LLMs are capable generalists, they excel when focused on a single, well-defined task.

In building my multi-agent search system, I divided the work into three precisely defined roles:

1. **Lead Agent**: The orchestrator responsible for overall search direction, task delegation, and shared memory management
2. **Search Agent**: A granular, single-purpose agent focused solely on web searches and communicating results through multiple search queries
3. **Answer Agent**: Synthesizes the final response using the initial query and curated shared memory context

> This granular delegation ensures each agent masters its domain rather than juggling multiple responsibilities.

## **Step Two: Think Like an Agent**

> To build effective agents, you must inhabit their perspective.

When designing the lead agent, I thought as an orchestrator would. What would I need?

<p align="center">
  <img src="/assets/lead-agent.png" alt="Thinking Like an Agent" width="70%">
</p>

- **Deliberation capability**: A mechanism to ponder and delegate tasks effectively achieved through reasoning abilities and tools to spawn multiple search agents
- **Quality control**: Search agents might return irrelevant data. Imagine searching for "perplexity loss function" and receiving results about Perplexity the company. Without filtering, this noise could derail the entire system. I built selective storage mechanisms so the lead agent curates what enters shared memory
- **Iterative exploration**: Search isn't single-shot. Humans build upon previous context, adjusting their trajectory as they learn. My lead agent can also spawn multiple search agents in loops until it finds what it needs. Sometimes it gets curious and explores tangentially (though I do set thresholds)

## **Step Three: Tokens Are Expensive (Optimization)**

> Multi-agent systems consume tokens voraciously. 

My approach: minimize the search model's output. Each search result gets a unique ID. When the research agent identifies useful results, it stores only the ID reference, Python code handles the actual storage. This eliminated redundant token generation where the research agent would otherwise regenerate large result chunks.

<p align="center">
  <img src="/assets/context-optimization.gif" alt="Optimization" width="100%">
</p>

> It's like using library call numbers instead of photocopying entire books, you get the same access with a fraction of the overhead.

### **Some interesting traces:**

> Taken directly from OpenAI's Trace Logs.

<details>
<summary><strong>Example: "When is GTA VI releasing? What can I expect?"</strong></summary>

```
User asks:
"When is GTA VI releasing? What can I expect?"

Research Agent begins task planning and delegation...

â”œâ”€â”€ Step 1: Sub-task: Find release date
â”‚   â”œâ”€â”€ Research Agent launches Search Agent
â”‚   â”‚   â†’ Query: "GTA VI release date"
â”‚   â””â”€â”€ Search Agent returns result:
â”‚       â†’ "GTA VI is officially set to release on May 26, 2026..."

â”œâ”€â”€ Step 2: Sub-task: Find expected features
â”‚   â”œâ”€â”€ Research Agent launches another Search Agent
â”‚   â”‚   â†’ Query: "GTA VI expected features and gameplay elements"
â”‚   â””â”€â”€ Search Agent returns result:
â”‚       â†’ "Expected features include multiple cities (Vice City), multiple protagonists, improved AI..."

â”œâ”€â”€ Step 3: Store findings in memory
â”‚   â”œâ”€â”€ Research Agent stores release date info
â”‚   â”‚   â†’ add_to_memory({ id: "01abf311-bce9..." })
â”‚   â””â”€â”€ Research Agent stores gameplay features info
â”‚       â†’ add_to_memory({ id: "ca011f09-6e7e..." })

â””â”€â”€ Step 4: Transfer to Answer Agent
    â””â”€â”€ Research Agent hands off task
        â†’ transfer_to_answer_agent()

Answer Agent receives memory and generates final response for the user.
```

</details>

<details>
<summary><strong>Example: "What's the current status of Texas floods?"</strong></summary>

```
User asks:
"What's the current status of Texas floods?"

Answer Agent begins...

â”œâ”€â”€ Step 1: Sub-task: Retrieve current info
â”‚   â”œâ”€â”€ Answer Agent launches Search Agent
â”‚   â”‚   â†’ Query: "Texas floods current status July 2025"
â”‚   â””â”€â”€ Search Agent returns result:
â”‚       â†’ "Severe flooding ongoing into July 2025; 79 dead, major damage in Kerr County..."

â”œâ”€â”€ Step 2: Transfer to Answer Agent (self-triggered, final stage)
â”‚   â””â”€â”€ Answer Agent prepares final user response
â”‚       â†’ Extracts summary from search results:
â”‚          - 79 confirmed deaths
â”‚          - 27 children missing from Camp Mystic
â”‚          - Governor declared disaster + federal aid
â”‚          - 400+ first responders deployed
â”‚          - Massive river rise and displacement

Final output: Concise report delivered to user.
```

</details>

<details>
<summary><strong>Example: "What is Big Beautiful Bill? Why is Elon against it?"</strong></summary>

```
User asks:
"What is Big Beautiful Bill? Why is Elon against it?"

Research Agent begins task planning and delegation...

â”œâ”€â”€ Step 1: Sub-task: Why is Elon Musk against the bill?
â”‚   â”œâ”€â”€ Research Agent launches Search Agent
â”‚   â”‚   â†’ Query: "Why is Elon Musk against big beautiful bill?"
â”‚   â””â”€â”€ Search Agent returns result:
â”‚       â†’ Musk calls it "utterly insane and destructive,"
â”‚         criticizes cuts to EV tax credits, and suggests forming a new party.

â”œâ”€â”€ Step 2: Sub-task: What is the Big Beautiful Bill?
â”‚   â”œâ”€â”€ Research Agent launches another Search Agent
â”‚   â”‚   â†’ Query: "What is the One Big Beautiful Bill proposed by Trump?"
â”‚   â””â”€â”€ Search Agent returns result:
â”‚       â†’ Bill includes:
â”‚           - Major tax cuts
â”‚           - Medicaid restrictions
â”‚           - Border wall funding
â”‚           - Elimination of clean energy incentives
â”‚           - $5T debt ceiling raise and $1.5T in cuts

â”œâ”€â”€ Step 3: Store findings in memory
â”‚   â”œâ”€â”€ Research Agent stores Elon Musk's response
â”‚   â”‚   â†’ add_to_memory({ id: "289e0869-c6cf..." })
â”‚   â””â”€â”€ Research Agent stores bill details
â”‚       â†’ add_to_memory({ id: "500606cd-69f9..." })

â””â”€â”€ Step 4: Transfer to Answer Agent
    â””â”€â”€ Research Agent hands off task
        â†’ transfer_to_answer_agent()

Answer Agent receives memory and generates final response for the user.
```

</details>

### **Looking Forward: Asynchronous Communication**

Current multi-agent systems lack true asynchronous execution. Real-world interactions are inherently asynchronous. Knowing *what* to say is only half the equation; knowing *when* to say it is equally crucial. That's the challenge I'm tackling next: teaching agents not just what to communicate, but when to break their silence.

## ðŸŽ¬ Bonus: Poogle Questions

**Starring Squid Game's Lee Jung-jae**

> **ðŸŽ¥ Watch here:** [Poogle Questions with Lee Jung-jae - YouTube](https://www.youtube.com/watch?v=7x0lu6ZscAg)

